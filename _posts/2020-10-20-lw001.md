---
title: "Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples"
style: post
categories: Paper NLP
---

摘要：我们重新审视神经时代语法分析器的领域自适应。首先，我们表明，当目标域和源域在句法上相似时，词表示的最新进展大大减少了域适应的需求。作为证据，我们在单独的Wall Street Journal数据上训练的分析器在Brown语料库上取得了高于90%的$F_1$分数。对于句法上距离更远的域，我们提供了一个简单的方式即只使用几十个部分注释来调整分析器。例如，我们仅用60个训练样本将留出集中的无错误几何域分析器的$F_1$从45%提高到了73%。在这个过程中，我们展示了一个在Wall Street Journal测试集上达到了94.3%的$F_1$分数的SOTA模型，这个模型的表现相比于之前SOTA模型的92.6%提高了1.7%的绝对值。
